Create Lambda function
aws lambda create-function \
  --function-name MyLambdaFunction \
  --runtime python3.8 \
  --role arn:aws:iam::your-account-id:role/execution_role \
  --handler index.handler \
  --zip-file fileb:///path/to/your/lambda_function.zip

Streaming body
  response = s3.get_object(Bucket=bucket_name, Key=file_key)
    with io.TextIOWrapper(response['Body'], encoding='utf-8') as f:
        while True:
            chunk = f.readlines(chunk_size)
            if not chunk:
                global flag
                flag = False
                break  # Exit the loop if the chunk is empty (end of file)
            yield chunk

Check if ecs task login is enabled
bash <( curl -Ls https://raw.githubusercontent.com/aws-containers/amazon-ecs-exec-checker/main/check-ecs-exec.sh )
 cluster_name_place_holder task-arn

Start session inside task image
 aws ssm start-session --target task-arn_place-holder


 Identify the Linux Distribution
 cat /etc/os-release

import json
import boto3

def lambda_handler(event, context):
    # Set your ECS cluster name
    cluster_name = 'DevCluster'
    
    subnet_id = 'subnet-'
    security_group_ids = ['sg-']

    # Set your ECS task definition ARN
    task_definition_arn = 'arn:aws:ecs:us-east-1:604830111080:task-definition/myfastapiapp:1'

   
    ecs_client = boto3.client('ecs')

    response = ecs_client.run_task(
        cluster=cluster_name,
        taskDefinition=task_definition_arn,
        launchType='FARGATE',
        networkConfiguration={
            'awsvpcConfiguration': {
                'subnets': [subnet_id],
                'securityGroups': security_group_ids,
                'assignPublicIp': 'ENABLED'
            }
        }
    )

    print(response)


    import os
import boto3

def lambda_handler(event, context):
    # Replace these values with your own S3 bucket and file information
    bucket_name = 'your-s3-bucket-name'
    key = 'path/to/your/file.txt'
    local_file_path = '/tmp/your-file.txt'  # Lambda has limited access to local storage, use /tmp directory

    try:
        # Create an S3 client
        s3 = boto3.client('s3')

        # Download the file from S3 to a local file in /tmp directory
        s3.download_file(bucket_name, key, local_file_path)
        print(f'Successfully downloaded file from S3 to {local_file_path}')

        # Check the size of the downloaded file
        file_size = os.path.getsize(local_file_path)
        print(f'Downloaded file size: {file_size} bytes')

        # Perform additional processing with the downloaded file if needed

        return {
            'statusCode': 200,
            'body': 'File downloaded successfully'
        }

    except Exception as e:
        print(f'Error downloading file: {e}')
        return {
            'statusCode': 500,
            'body': 'Error downloading file'
        }




